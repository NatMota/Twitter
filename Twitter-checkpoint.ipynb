{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from requests_html import HTMLSession, HTML\n",
    "from datetime import datetime\n",
    "\n",
    "session = HTMLSession()\n",
    "\n",
    "\n",
    "def get_tweets(user, pages=25):\n",
    "    \"\"\"Gets tweets for a given user, via the Twitter frontend API.\"\"\"\n",
    "\n",
    "    url = f'https://twitter.com/i/profiles/show/{user}/timeline/tweets?include_available_features=1&include_entities=1&include_new_items_bar=true'\n",
    "    headers = {\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "        'Referer': f'https://twitter.com/{user}',\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8',\n",
    "        'X-Twitter-Active-User': 'yes',\n",
    "        'X-Requested-With': 'XMLHttpRequest'\n",
    "    }\n",
    "\n",
    "    def gen_tweets(pages):\n",
    "        r = session.get(url, headers=headers)\n",
    "\n",
    "        while pages > 0:\n",
    "            try:\n",
    "                html = HTML(html=r.json()['items_html'],\n",
    "                            url='bunk', default_encoding='utf-8')\n",
    "            except KeyError:\n",
    "                raise ValueError(\n",
    "                    f'Oops! Either \"{user}\" does not exist or is private.')\n",
    "\n",
    "            comma = \",\"\n",
    "            dot = \".\"\n",
    "            tweets = []\n",
    "            for tweet in html.find('.stream-item'):\n",
    "                text = tweet.find('.tweet-text')[0].full_text\n",
    "                tweetId = tweet.find(\n",
    "                    '.js-permalink')[0].attrs['data-conversation-id']\n",
    "                time = datetime.fromtimestamp(\n",
    "                    int(tweet.find('._timestamp')[0].attrs['data-time-ms'])/1000.0)\n",
    "                interactions = [x.text for x in tweet.find(\n",
    "                    '.ProfileTweet-actionCount')]\n",
    "                replies = int(interactions[0].split(\" \")[0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                retweets = int(interactions[1].split(\" \")[\n",
    "                               0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                likes = int(interactions[2].split(\" \")[0].replace(comma, \"\").replace(dot,\"\"))\n",
    "                hashtags = [hashtag_node.full_text for hashtag_node in tweet.find('.twitter-hashtag')]\n",
    "                urls = [url_node.attrs['data-expanded-url'] for url_node in tweet.find('a.twitter-timeline-link:not(.u-hidden)')]\n",
    "                photos = [photo_node.attrs['data-image-url'] for photo_node in tweet.find('.AdaptiveMedia-photoContainer')]\n",
    "                \n",
    "                videos = []\n",
    "                video_nodes = tweet.find(\".PlayableMedia-player\")\n",
    "                for node in video_nodes:\n",
    "                    styles = node.attrs['style'].split()\n",
    "                    for style in styles:\n",
    "                        if style.startswith('background'):\n",
    "                            tmp = style.split('/')[-1]\n",
    "                            video_id = tmp[:tmp.index('.jpg')]\n",
    "                            videos.append({'id': video_id})\n",
    "                tweets.append({'tweetId': tweetId, 'time': time, 'text': text,\n",
    "                               'replies': replies, 'retweets': retweets, 'likes': likes, \n",
    "                               'entries': {\n",
    "                                    'hashtags': hashtags, 'urls': urls,\n",
    "                                    'photos': photos, 'videos': videos\n",
    "                                }\n",
    "                               })\n",
    "\n",
    "            last_tweet = html.find('.stream-item')[-1].attrs['data-item-id']\n",
    "\n",
    "            for tweet in tweets:\n",
    "                if tweet:\n",
    "                    tweet['text'] = re.sub('http', ' http', tweet['text'], 1)\n",
    "                    yield tweet\n",
    "\n",
    "            r = session.get(\n",
    "                url, params = {'max_position': last_tweet}, headers = headers)\n",
    "            pages += -1\n",
    "\n",
    "    yield from gen_tweets(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-b3ef915f58c5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-b3ef915f58c5>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    for tweet in get_tweets('OisforOctopus', pages=25)]\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "d = df[[text, tweetId, time, interactions,replies,retweets,likes,hashtags,urls,photos,videos()] /\n",
    "    for tweet in get_tweets('OisforOctopus', pages=25)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = get_tweets('OisforOctopus',pages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entries</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>tweetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'hashtags': ['#OVPortfolio'], 'urls': [], 'ph...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"As an AI business, it is our responsibility t...</td>\n",
       "      <td>2018-10-31 13:30:39</td>\n",
       "      <td>1057625901213642755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'hashtags': ['#Halloween', '#SofarSounds', '#...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Need plans for #Halloween, a birthday gift or ...</td>\n",
       "      <td>2018-10-31 15:58:21</td>\n",
       "      <td>1057663071328575489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'hashtags': ['#Support', '#London', '#Event',...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Weâ€™re delighted that our Mullingar Primary Car...</td>\n",
       "      <td>2018-10-31 15:21:11</td>\n",
       "      <td>1057653718731112448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://octopus.bre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you want to work for a company that is driv...</td>\n",
       "      <td>2018-10-26 17:45:38</td>\n",
       "      <td>1055863034093158402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://octopus.ene...</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Agile Octopus, the first half-hourly time of u...</td>\n",
       "      <td>2018-10-26 11:52:56</td>\n",
       "      <td>1055774272281604098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://octopusgrou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Luke Hakes explains why the new Octopus Ventur...</td>\n",
       "      <td>2018-10-26 12:12:02</td>\n",
       "      <td>1055779076923899904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'hashtags': ['#EmiratesStadium'], 'urls': [],...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Since starting their partnership with us, @Ars...</td>\n",
       "      <td>2018-10-24 18:06:00</td>\n",
       "      <td>1055143380131438596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'hashtags': [], 'urls': [], 'photos': [], 'vi...</td>\n",
       "      <td>594</td>\n",
       "      <td>10</td>\n",
       "      <td>214</td>\n",
       "      <td>We helped @Arsenal become the first Premier Le...</td>\n",
       "      <td>2018-10-24 16:47:52</td>\n",
       "      <td>1055123718203236354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'hashtags': ['#education', '#OVPortfolio'], '...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Jolt provides a fresh approach to combining on...</td>\n",
       "      <td>2018-10-25 11:30:25</td>\n",
       "      <td>1055406215897980928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'hashtags': ['#EY', '#EOY20years'], 'urls': [...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Love this from our 2017 #EY Entrepreneur Of Th...</td>\n",
       "      <td>2018-10-22 10:46:28</td>\n",
       "      <td>1054307993087606784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://octopusgrou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter can be an isolating and worrying time f...</td>\n",
       "      <td>2018-10-24 15:13:15</td>\n",
       "      <td>1055099907990794240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://taxi.octopu...</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>Calling all licenced taxi drivers: green is th...</td>\n",
       "      <td>2018-10-24 11:07:00</td>\n",
       "      <td>1055037935773511680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'hashtags': [], 'urls': ['http://www.cityam.c...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>â€œWe donâ€™t want to be a company of two entrepre...</td>\n",
       "      <td>2018-10-22 09:30:44</td>\n",
       "      <td>1054288934321221633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://octopusgrou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Companies used to be able to profit from compl...</td>\n",
       "      <td>2018-10-19 15:30:37</td>\n",
       "      <td>1053292337038798848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'hashtags': [], 'urls': [], 'photos': [], 'vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alliott Cole: â€œVenture capital used to be opaq...</td>\n",
       "      <td>2018-10-19 10:40:48</td>\n",
       "      <td>1053219404354338817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'hashtags': ['#business', '#NEentrepreneurs']...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Chris Hulatt launched @OisforOctopus from his ...</td>\n",
       "      <td>2018-10-19 09:22:46</td>\n",
       "      <td>1053199767248007168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'hashtags': ['#vegan'], 'urls': [], 'photos':...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cut the crap: the #vegan case for anaerobic di...</td>\n",
       "      <td>2018-10-18 16:48:16</td>\n",
       "      <td>1052949491412885504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'hashtags': ['#development', '#primarycare', ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Weâ€™re proud to announce our Â£35+ million deal ...</td>\n",
       "      <td>2018-10-18 14:10:30</td>\n",
       "      <td>1052909787569184768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'hashtags': [], 'urls': ['https://octopusgrou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Has capitalism stopped being a force for good ...</td>\n",
       "      <td>2018-10-18 16:04:45</td>\n",
       "      <td>1052938540487561216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'hashtags': ['#GreenGB'], 'urls': [], 'photos...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>To mark the ten-year anniversary of the Climat...</td>\n",
       "      <td>2018-10-18 12:15:06</td>\n",
       "      <td>1052880745935589376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              entries  likes  replies  \\\n",
       "0   {'hashtags': ['#OVPortfolio'], 'urls': [], 'ph...      1        0   \n",
       "1   {'hashtags': ['#Halloween', '#SofarSounds', '#...      0        0   \n",
       "2   {'hashtags': ['#Support', '#London', '#Event',...      2        0   \n",
       "3   {'hashtags': [], 'urls': ['https://octopus.bre...      1        0   \n",
       "4   {'hashtags': [], 'urls': ['https://octopus.ene...     29        3   \n",
       "5   {'hashtags': [], 'urls': ['https://octopusgrou...      0        0   \n",
       "6   {'hashtags': ['#EmiratesStadium'], 'urls': [],...      9        0   \n",
       "7   {'hashtags': [], 'urls': [], 'photos': [], 'vi...    594       10   \n",
       "8   {'hashtags': ['#education', '#OVPortfolio'], '...      4        0   \n",
       "9   {'hashtags': ['#EY', '#EOY20years'], 'urls': [...      7        0   \n",
       "10  {'hashtags': [], 'urls': ['https://octopusgrou...      1        0   \n",
       "11  {'hashtags': [], 'urls': ['https://taxi.octopu...     12        8   \n",
       "12  {'hashtags': [], 'urls': ['http://www.cityam.c...     16        0   \n",
       "13  {'hashtags': [], 'urls': ['https://octopusgrou...      0        0   \n",
       "14  {'hashtags': [], 'urls': [], 'photos': [], 'vi...      0        0   \n",
       "15  {'hashtags': ['#business', '#NEentrepreneurs']...      1        0   \n",
       "16  {'hashtags': ['#vegan'], 'urls': [], 'photos':...      0        0   \n",
       "17  {'hashtags': ['#development', '#primarycare', ...      4        0   \n",
       "18  {'hashtags': [], 'urls': ['https://octopusgrou...      1        0   \n",
       "19  {'hashtags': ['#GreenGB'], 'urls': [], 'photos...      1        0   \n",
       "\n",
       "    retweets                                               text  \\\n",
       "0          1  \"As an AI business, it is our responsibility t...   \n",
       "1          2  Need plans for #Halloween, a birthday gift or ...   \n",
       "2          1  Weâ€™re delighted that our Mullingar Primary Car...   \n",
       "3          1  Do you want to work for a company that is driv...   \n",
       "4         15  Agile Octopus, the first half-hourly time of u...   \n",
       "5          0  Luke Hakes explains why the new Octopus Ventur...   \n",
       "6          3  Since starting their partnership with us, @Ars...   \n",
       "7        214  We helped @Arsenal become the first Premier Le...   \n",
       "8          1  Jolt provides a fresh approach to combining on...   \n",
       "9          3  Love this from our 2017 #EY Entrepreneur Of Th...   \n",
       "10         1  Winter can be an isolating and worrying time f...   \n",
       "11        16  Calling all licenced taxi drivers: green is th...   \n",
       "12         6  â€œWe donâ€™t want to be a company of two entrepre...   \n",
       "13         0  Companies used to be able to profit from compl...   \n",
       "14         0  Alliott Cole: â€œVenture capital used to be opaq...   \n",
       "15         1  Chris Hulatt launched @OisforOctopus from his ...   \n",
       "16         0  Cut the crap: the #vegan case for anaerobic di...   \n",
       "17         1  Weâ€™re proud to announce our Â£35+ million deal ...   \n",
       "18         0  Has capitalism stopped being a force for good ...   \n",
       "19         0  To mark the ten-year anniversary of the Climat...   \n",
       "\n",
       "                  time              tweetId  \n",
       "0  2018-10-31 13:30:39  1057625901213642755  \n",
       "1  2018-10-31 15:58:21  1057663071328575489  \n",
       "2  2018-10-31 15:21:11  1057653718731112448  \n",
       "3  2018-10-26 17:45:38  1055863034093158402  \n",
       "4  2018-10-26 11:52:56  1055774272281604098  \n",
       "5  2018-10-26 12:12:02  1055779076923899904  \n",
       "6  2018-10-24 18:06:00  1055143380131438596  \n",
       "7  2018-10-24 16:47:52  1055123718203236354  \n",
       "8  2018-10-25 11:30:25  1055406215897980928  \n",
       "9  2018-10-22 10:46:28  1054307993087606784  \n",
       "10 2018-10-24 15:13:15  1055099907990794240  \n",
       "11 2018-10-24 11:07:00  1055037935773511680  \n",
       "12 2018-10-22 09:30:44  1054288934321221633  \n",
       "13 2018-10-19 15:30:37  1053292337038798848  \n",
       "14 2018-10-19 10:40:48  1053219404354338817  \n",
       "15 2018-10-19 09:22:46  1053199767248007168  \n",
       "16 2018-10-18 16:48:16  1052949491412885504  \n",
       "17 2018-10-18 14:10:30  1052909787569184768  \n",
       "18 2018-10-18 16:04:45  1052938540487561216  \n",
       "19 2018-10-18 12:15:06  1052880745935589376  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'header'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-19a9ce557b39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'OisforOctopus'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfoo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'header'"
     ]
    }
   ],
   "source": [
    "for tweet in get_tweets('OisforOctopus', pages=25):\n",
    "    foo = pd.DataFrame(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
